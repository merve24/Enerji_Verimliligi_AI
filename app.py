# Streamlit web uygulamasÄ±nÄ±n ana dosyasÄ±
import streamlit as st
from google import genai
import numpy as np
import os
# data.py dosyasÄ±ndaki fonksiyonu iÃ§e aktarÄ±yoruz
from data import prepare_rag_data 

# --- 1. SABÄ°T VERÄ°LERÄ° VE BAÄLANTILARI TANIMLAMA ---

# Dosya adÄ±, hata mesajlarÄ±nda doÄŸru adÄ±n gÃ¶rÃ¼nmesi iÃ§in burada tanÄ±mlanÄ±r.
CORRECT_FILE_NAME = "Enerji_verimliligi_eÄŸitim_kitabi.txt"

# Streamlit API AnahtarÄ±nÄ± Streamlit Secrets'tan alacak
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"] 
except Exception as e:
    st.error(f"API AnahtarÄ± YÃ¼klenemedi: LÃ¼tfen Streamlit Cloud Secrets'ta GEMINI_API_KEY'i tanÄ±mladÄ±ÄŸÄ±nÄ±zdan emin olun. Hata: {e}")
    st.stop()
    
# Cache kullanarak verinin sadece BÄ°R KEZ yÃ¼klenmesini saÄŸlÄ±yoruz
@st.cache_resource(ttl=900) 
def load_rag_data(api_key):
    # data.py dosyasÄ±ndaki ana fonksiyonu Ã§aÄŸÄ±rÄ±r ve FAISS indexini yÃ¼kler
    return prepare_rag_data(api_key)

# Veri yÃ¼kleme fonksiyonunu API key ile Ã§aÄŸÄ±rÄ±yoruz.
# FAISS indeks dosyalarÄ± (faiss_index.bin ve text_chunks.npy) GitHub'da olduÄŸu iÃ§in,
# bu iÅŸlem artÄ±k saniyeler iÃ§inde tamamlanacaktÄ±r.
text_chunks, index = load_rag_data(GEMINI_API_KEY) 

# EÄŸer data.py hata yakalayÄ±p boÅŸ dÃ¶ndÃ¼rÃ¼rse, burada uygulamayÄ± durdururuz.
if index is None:
    st.error(f"Veri seti yÃ¼klenemedi. LÃ¼tfen '{CORRECT_FILE_NAME}' dosyasÄ±nÄ±n GitHub'da app.py ve data.py ile aynÄ± dizinde bulunduÄŸundan emin olun.")
    st.stop()

# Client'Ä± sadece Gemini modelini Ã§aÄŸÄ±rmak iÃ§in bir kez tanÄ±mlÄ±yoruz.
client = genai.Client(api_key=GEMINI_API_KEY) 


# --- 2. RAG Sorgu Fonksiyonu ---
# k=8'e yÃ¼kseltildi (daha fazla ve kÃ¼Ã§Ã¼k parÃ§a Ã§ekmek iÃ§in)
def rag_query_streamlit(query, k=8): 
    
    # 2A. Sorguyu VektÃ¶rleÅŸtirme (Retrieval)
    
    response_embedding = client.models.embed_content(
        model='text-embedding-004',
        contents=[query]
        # NOT: data.py dosyasÄ±ndaki gibi 'task_type' kullanÄ±lmadÄ±, 
        # Ã§Ã¼nkÃ¼ sorgu iÃ§in varsayÄ±lan 'RETRIEVAL_QUERY' yeterlidir.
    )
    
    # KRÄ°TÄ°K DÃœZELTME: API yanÄ±tÄ±nÄ±n yapÄ±sÄ± ne olursa olsun (sÃ¶zlÃ¼k veya nesne), 
    # doÄŸrudan vektÃ¶r listesine eriÅŸmek iÃ§in bu yapÄ±yÄ± kullanÄ±yoruz.
    # Bu, .embedding[0] (AttributeError) ve ['embedding'][0] (TypeError) sorunlarÄ±nÄ± Ã§Ã¶zmelidir.
    # VarsayÄ±m: Ya listeye eriÅŸmek iÃ§in .embedding[0] ya da sÃ¶zlÃ¼ÄŸe eriÅŸmek iÃ§in ['embedding'][0] Ã§alÄ±ÅŸmalÄ±ydÄ±.
    # EÄŸer ikisi de Ã§alÄ±ÅŸmÄ±yorsa, client'Ä±n dÃ¶ndÃ¼rdÃ¼ÄŸÃ¼ yapÄ±nÄ±n direkt listenin ilk elemanÄ± olduÄŸunu varsayÄ±yoruz.
    # Ancak en gÃ¼venli yÃ¶ntem, .embedding ile dÃ¶nen yapÄ±nÄ±n ilk elemanÄ±nÄ± almaktÄ±r. 
    # Son denememiz olan .embedding[0] baÅŸarÄ±sÄ±z olduÄŸundan, ilk Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda baÅŸarÄ±lÄ± olan yapÄ±yÄ± kullanmalÄ±yÄ±z.
    
    # Geri dÃ¶nÃ¼len nesneden 'embedding' listesinin ilk elemanÄ±nÄ± alÄ±yoruz.
    # Bu, en gÃ¼venilir ve tutarlÄ± yÃ¶ntem olmalÄ±dÄ±r.
    query_embedding = response_embedding.embedding[0] if hasattr(response_embedding, 'embedding') else response_embedding['embedding'][0]
    
    # Ancak pydantic hatasÄ± aldÄ±ÄŸÄ± iÃ§in, bu nesnenin sadece sÃ¶zlÃ¼k olarak ele alÄ±nmasÄ± gereken bir yapÄ±sÄ± olabilir.
    # En baÅŸÄ±ndan baÅŸarÄ±lÄ± olan .embeddings[0].values yapÄ±sÄ±nÄ±, .embedding[0] olarak deÄŸiÅŸtirdik.
    # Åimdi hatanÄ±n tam kaynaÄŸÄ±nÄ± gidermek iÃ§in, dÃ¶nen yanÄ±ttan 'embedding' Ã¶zelliÄŸini alÄ±p ilk elemanÄ±nÄ± Ã§Ä±karÄ±yoruz.
    # EÄŸer data.py'de response['embedding'] Ã§alÄ±ÅŸÄ±yorsa, burada da bu yapÄ±yÄ± kullanmayÄ± deniyoruz.
    
    # YENÄ° DENEME (En sÄ±k Ã§alÄ±ÅŸan yapÄ±ya geri dÃ¶nÃ¼yoruz, ilk baÅŸarÄ±sÄ±z olanÄ± gÃ¶z ardÄ± ederek):
    # Bu, bir Ã¶nceki TypeError hatasÄ±nÄ± vermiÅŸti, ancak .embedding hatasÄ±ndan daha yakÄ±ndÄ±r.
    # Bu kez, dÃ¶nen yanÄ±tÄ±n bir listeye Ã§evrilmesi gerekebilir.
    
    # ğŸ’¥ KESÄ°N DÃœZELTME DENEMESÄ° (En tutarlÄ± yapÄ±yÄ± kullanma):
    # VektÃ¶rleÅŸtirme API'si tek bir metin gÃ¶nderildiÄŸinde bile bir liste dÃ¶ndÃ¼rebilir.
    # Bu sefer, .embedding Ã¶zelliÄŸini kullanÄ±p, listenin ilk elemanÄ±nÄ± (vektÃ¶r dizisi) alÄ±yoruz.
    try:
        query_embedding = response_embedding.embedding[0]
    except AttributeError:
        # EÄŸer AttributeError alÄ±yorsa, nesne yerine sÃ¶zlÃ¼k dÃ¶ndÃ¼.
        try:
            query_embedding = response_embedding['embedding'][0]
        except KeyError:
            # En kÃ¶tÃ¼ durumda, dÃ¶ndÃ¼rÃ¼len yapÄ±nÄ±n doÄŸrudan listelenmiÅŸ vektÃ¶rler olduÄŸunu varsayÄ±yoruz.
            query_embedding = response_embedding[0]
        
    # FAISS'te en yakÄ±n parÃ§alarÄ± arama
    # FAISS, (1, 1536) boyutunda bir array bekler.
    D, I = index.search(np.array([query_embedding], dtype='float32'), k)
    
    # 2C. ParÃ§alarÄ± metin olarak birleÅŸtirme
    retrieved_text = "\n---\n".join([text_chunks[i] for i in I[0]])
    
    # 2D. Prompt oluÅŸturma (AkÄ±l YÃ¼rÃ¼tmeye Ä°zin Veren ANCAK HalÃ¼sinasyonu Engelleyen Prompt)
    prompt = f"""
    Sen, "Enerji VerimliliÄŸi EÄŸitim KitabÄ±"ndan bilgi alan uzman bir danÄ±ÅŸmansÄ±n. 
    Senin tek bilgi kaynaÄŸÄ±n aÅŸaÄŸÄ±daki BaÄŸlam (Context) iÃ§inde yer alan metinlerdir.

    1. **AKIL YÃœRÃœTME:** Kitaptan Ã‡ekilen Kaynaklar Ä±ÅŸÄ±ÄŸÄ±nda, akÄ±l yÃ¼rÃ¼terek kapsamlÄ± ve kiÅŸiselleÅŸtirilmiÅŸ bir cevap Ã¼ret. CevabÄ±nÄ±n doÄŸruluÄŸu, sadece bu kaynaklara dayanmalÄ±dÄ±r.
    2. **KAYNAK KISITLAMASI:** BaÄŸlamda soruya net ve doÄŸrudan cevap verecek bilgi **bulunmuyorsa**, **KESÄ°NLÄ°KLE KENDÄ° GENEL BÄ°LGÄ°NÄ° KULLANMA** ve akÄ±l yÃ¼rÃ¼tmeye Ã§alÄ±ÅŸma.
    3. **RED YANITI:** EÄŸer cevap veremeyeceksen, yanÄ±tÄ±n: "Bu konuda eÄŸitim kitabÄ±mda yeterli ve gÃ¼ncel bilgi bulunmamaktadÄ±r." ÅŸeklinde olmalÄ±dÄ±r.

    CevabÄ±nÄ± anlaÅŸÄ±lÄ±r, profesyonel bir dille ve ilgili emojilerle sun.
    
    ---
    
    BaÄŸlam (Kitaptan Ã‡ekilen Kaynaklar):
    {retrieved_text}

    ---
    
    Soru:
    {query}
    """
    
    # 2E. Cevap Ãœretme (Generation)
    response = client.models.generate_content(
        model='gemini-2.5-flash',
        contents=prompt
    )
    
    return response.text, retrieved_text

# --- 3. UYGULAMA MANTIÄI VE ARAYÃœZ ---
st.set_page_config(
    page_title="Enerji VerimliliÄŸi AI", 
    page_icon="ğŸ’¡", 
    layout="wide"
)

# Yeni isim ve aÃ§Ä±klama buraya eklendi
st.title("ğŸ’¡ Enerji VerimliliÄŸi AI Chatbot")
st.markdown("Enerji dÃ¼nyasÄ±ndaki 1000 sayfalÄ±k ğŸ“š bilgelik parmaklarÄ±nÄ±zÄ±n ucunda. Bu uzman ğŸ¤– AI, size en gÃ¼ncel ve gÃ¼venilir bilgileri anÄ±nda sunar.")

# Session State ile mesaj geÃ§miÅŸini yÃ¶netme
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Merhaba! Enerji verimliliÄŸi ve sÃ¼rdÃ¼rÃ¼lebilirlik konularÄ±nda sorularÄ±nÄ±zÄ± yanÄ±tlamaya hazÄ±rÄ±m. Size nasÄ±l yardÄ±mcÄ± olabilirim? âš¡"}]

# Mesaj geÃ§miÅŸini arayÃ¼ze yazdÄ±rma
for msg in st.session_state.messages:
    # Emojilerle rol belirleme
    avatar = "ğŸ’¡" if msg["role"] == "assistant"] else "ğŸ‘¤"
    st.chat_message(msg["role"], avatar=avatar).write(msg["content"])

# KullanÄ±cÄ± giriÅŸi ve cevap Ã¼retme
if prompt := st.chat_input("Enerji verimliliÄŸi, sÃ¼rdÃ¼rÃ¼lebilirlik veya Ã§evre hakkÄ±nda bir soru sorun... ğŸ“"):
    # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle ve yazdÄ±r
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user", avatar="ğŸ‘¤").write(prompt)

    # Asistan cevabÄ±nÄ± Ã¼retme
    with st.chat_message("assistant", avatar="ğŸ’¡"):
        with st.spinner("Enerji VerimliliÄŸi KitabÄ± taranÄ±yor ve akÄ±l yÃ¼rÃ¼tÃ¼lÃ¼yor... ğŸ§ "):
            response, source = rag_query_streamlit(prompt)

        st.markdown(response)

        # RAG kaynaÄŸÄ±nÄ± gÃ¶sterme (ÅeffaflÄ±k iÃ§in)
        with st.expander("ğŸ” KullanÄ±lan Kaynak (RAG Retrieval)"):
            st.code(source, language='text')

    # Asistan cevabÄ±nÄ± geÃ§miÅŸe ekle
    st.session_state.messages.append({"role": "assistant", "content": response})
