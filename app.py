# Streamlit web uygulamasÄ±nÄ±n ana dosyasÄ±
import streamlit as st
from google import genai
# import numpy kaldÄ±rÄ±ldÄ±
import os
# data.py dosyasÄ±ndaki fonksiyonu iÃ§e aktarÄ±yoruz
from data import prepare_rag_data 

# --- 1. SABÄ°T VERÄ°LERÄ° VE BAÄLANTILARI TANIMLAMA ---

CORRECT_FILE_NAME = "Enerji_verimliligi_eÄŸitim_kitabi.txt"

# Streamlit API AnahtarÄ±nÄ± Streamlit Secrets'tan alacak
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"] 
except Exception as e:
    st.error(f"API AnahtarÄ± YÃ¼klenemedi: LÃ¼tfen Streamlit Cloud Secrets'ta GEMINI_API_KEY'i tanÄ±mladÄ±ÄŸÄ±nÄ±zdan emin olun. Hata: {e}")
    st.stop()
    
# Cache kaldÄ±rÄ±ldÄ±.
def load_rag_data(api_key):
    # data.py dosyasÄ±ndaki ana fonksiyonu Ã§aÄŸÄ±rÄ±r ve metin parÃ§alarÄ±nÄ± yÃ¼kler
    return prepare_rag_data(api_key)

# Veri yÃ¼kleme fonksiyonunu API key ile Ã§aÄŸÄ±rÄ±yoruz.
# index_placeholder, data.py'den gelen None deÄŸerini tutar.
text_chunks, index_placeholder = load_rag_data(GEMINI_API_KEY) 

# EÄŸer data.py hata yakalayÄ±p boÅŸ dÃ¶ndÃ¼rÃ¼rse, burada uygulamayÄ± durdururuz.
if not text_chunks:
    st.error(f"Veri seti yÃ¼klenemedi. LÃ¼tfen '{CORRECT_FILE_NAME}' dosyasÄ±nÄ±n GitHub'da olduÄŸundan ve data.py'nin gÃ¼ncel olduÄŸundan emin olun.")
    st.stop()

# Client'Ä± sadece Gemini modelini Ã§aÄŸÄ±rmak iÃ§in bir kez tanÄ±mlÄ±yoruz.
client = genai.Client(api_key=GEMINI_API_KEY) 

# --- 2. TEMEL SORGULAMA FONKSÄ°YONU (RAG KaldÄ±rÄ±ldÄ±) ---
def simple_query_streamlit(query): 
    
    # FAISS ARAMASI VE VEKTÃ–RLEÅTÄ°RME KALDIRILDI.
    # Sadece ilk 1000 karakteri (text_chunks[0]) baÄŸlam olarak kullanÄ±lÄ±r.
    retrieved_text = text_chunks[0] 
    
    # Prompt oluÅŸturma
    prompt = f"""
    Sen, "Enerji VerimliliÄŸi EÄŸitim KitabÄ±"ndan bilgi alan uzman bir danÄ±ÅŸmansÄ±n. 
    Senin tek bilgi kaynaÄŸÄ±n aÅŸaÄŸÄ±daki BaÄŸlam (Context) iÃ§inde yer alan metinlerdir.

    1. **AKIL YÃœRÃœTME:** Kitaptan Ã‡ekilen Kaynaklar Ä±ÅŸÄ±ÄŸÄ±nda, kapsamlÄ± bir cevap Ã¼ret. CevabÄ±nÄ±n doÄŸruluÄŸu, sadece bu kaynaklara dayanmalÄ±dÄ±r.
    2. **KAYNAK KISITLAMASI:** BaÄŸlamda soruya net ve doÄŸrudan cevap verecek bilgi **bulunmuyorsa**, yanÄ±tÄ±n: "Bu konuda eÄŸitim kitabÄ±mda yeterli ve gÃ¼ncel bilgi bulunmamaktadÄ±r." ÅŸeklinde olmalÄ±dÄ±r.

    CevabÄ±nÄ± anlaÅŸÄ±lÄ±r, profesyonel bir dille ve ilgili emojilerle sun.
    
    ---
    
    BaÄŸlam (Kitaptan Ã‡ekilen Kaynaklar - Sadece Ä°lk 1000 Karakter):
    {retrieved_text}

    ---
    
    Soru:
    {query}
    """
    
    # Cevap Ãœretme (Generation)
    response = client.models.generate_content(
        model='gemini-1.5-flash',
        contents=prompt
    )
    
    return response.text, retrieved_text

# --- 3. UYGULAMA MANTIÄI VE ARAYÃœZ ---
st.set_page_config(page_title="Enerji VerimliliÄŸi AI", page_icon="ğŸ’¡", layout="wide")
st.title("ğŸ’¡ Enerji VerimliliÄŸi AI Chatbot")
st.markdown("Enerji dÃ¼nyasÄ±ndaki bilgelik parmaklarÄ±nÄ±zÄ±n ucunda. Åu an sadece kitabÄ±n **giriÅŸ bÃ¶lÃ¼mÃ¼ne** eriÅŸim vardÄ±r. âš¡")

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Merhaba! Enerji verimliliÄŸi konularÄ±nda sorularÄ±nÄ±zÄ± yanÄ±tlamaya hazÄ±rÄ±m. Åu an sadece **sÄ±nÄ±rlÄ± bir iÃ§eriÄŸe** eriÅŸimim var. âš¡"}]

for msg in st.session_state.messages:
    avatar = "ğŸ’¡" if msg["role"] == "assistant" else "ğŸ‘¤" 
    st.chat_message(msg["role"], avatar=avatar).write(msg["content"])

if prompt := st.chat_input("Enerji verimliliÄŸi hakkÄ±nda bir soru sorun... ğŸ“"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user", avatar="ğŸ‘¤").write(prompt)

    # Spinner'Ä±, chat_message'Ä±n dÄ±ÅŸÄ±na taÅŸÄ±yarak DOM hatasÄ±nÄ± Ã§Ã¶zÃ¼yoruz.
    with st.spinner("KitabÄ±n sÄ±nÄ±rlÄ± bÃ¶lÃ¼mÃ¼ taranÄ±yor ve cevap Ã¼retiliyor... ğŸ§ "):
        response, source = simple_query_streamlit(prompt)

    # Cevap, spinner bittikten sonra chat_message iÃ§inde yazdÄ±rÄ±lÄ±yor
    with st.chat_message("assistant", avatar="ğŸ’¡"):
        st.markdown(response)

        with st.expander("ğŸ” KullanÄ±lan Kaynak (Sadece Ä°lk 1000 Karakter)"):
            st.code(source, language='text')

    st.session_state.messages.append({"role": "assistant", "content": response})