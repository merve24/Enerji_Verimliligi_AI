import streamlit as st
from google import genai
import numpy as np
import os
from data import prepare_rag_data # YENÄ°: data.py dosyasÄ±nÄ± iÃ§e aktardÄ±k

# --- 1. SABÄ°T VERÄ°LERÄ° VE BAÄLANTILARI TANIMLAMA ---

# Cache kullanarak verinin sadece BÄ°R KEZ yÃ¼klenmesini saÄŸlÄ±yoruz
@st.cache_resource
def load_rag_data():
    # Bu fonksiyon, Streamlit her Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda data.py dosyasÄ±nÄ± Ã§aÄŸÄ±racak.
    return prepare_rag_data()

text_chunks, index = load_rag_data()

# Gemini API AnahtarÄ±nÄ± Streamlit Secrets'tan alacak
try:
    # Streamlit Cloud'da secret olarak tanÄ±mlanacak
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"] 
except:
    # Lokal test iÃ§in ortam deÄŸiÅŸkeninden alÄ±r
    GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY') 

client = genai.Client(api_key=GEMINI_API_KEY)


# --- 2. RAG FONKSÄ°YONUNU TANIMLAMA ---
def rag_query_streamlit(query, top_k=3, text_chunks=text_chunks, index=index):
    # Bu fonksiyon iÃ§i bir Ã¶nceki Ã§alÄ±ÅŸan kodunuzdur.
    
    # 5A. Sorguyu VektÃ¶rleÅŸtirme
    query_embedding_response = client.models.embed_content(
        model='text-embedding-004',
        contents=[query] 
    )
    query_embedding = np.array(query_embedding_response.embeddings[0].values, dtype='float32').reshape(1, -1)

    # 5B. VeritabanÄ±ndan AlakalÄ± Bilgiyi Ã‡ekme (Retrieval)
    distances, indices = index.search(query_embedding, top_k)
    retrieved_text = "".join(text_chunks[i] + "\n---\n" for i in indices[0])

    # 5C. Prompt OluÅŸturma
    prompt = f"""...[PROMPT METNÄ°NÄ°Z BURAYA GELECEK]..."""
    # (Uzun prompt metnini yer kazanmak iÃ§in buraya yazmÄ±yorum, eski app.py'den kopyalayÄ±n)
    
    prompt = f"""
    Sen, 'SÃ¼rdÃ¼rÃ¼lebilir Ä°ÅŸletme Enerji DanÄ±ÅŸmanÄ±' adlÄ± RAG temelli bir yapay zeka chatbot'usun.
    AÅŸaÄŸÄ±daki 'BaÄŸlam' kÄ±smÄ±nda sana verilen bilgileri kullanarak, 'Soru' kÄ±smÄ±ndaki kullanÄ±cÄ± sorusunu yanÄ±tla.
    CevabÄ±nÄ± yalnÄ±zca sana verilen baÄŸlamdaki bilgilere dayanarak ver. EÄŸer baÄŸlamda cevap yoksa,
    "Bu sorunun cevabÄ±na sahip olduÄŸum Enerji VerimliliÄŸi KitabÄ±nda net bir bilgi bulunmamaktadÄ±r." diye cevap ver.
    CevabÄ±nÄ± anlaÅŸÄ±lÄ±r ve profesyonel bir dille sun.

    ---
    
    BaÄŸlam:
    {retrieved_text}

    ---
    
    Soru:
    {query}
    """
    
    # 5D. Cevap Ãœretme (Generation)
    response = client.models.generate_content(
        model='gemini-2.5-flash',
        contents=prompt
    )
    
    return response.text, retrieved_text

# --- 3. UYGULAMA MANTIÄI VE ARAYÃœZ ---
st.title("ğŸ’¡ Enerji VerimliliÄŸi RAG Chatbot'u")

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Merhaba! Enerji verimliliÄŸi hakkÄ±nda sorularÄ±nÄ±zÄ± yanÄ±tlamak iÃ§in buradayÄ±m."}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("Enerji verimliliÄŸi veya sÃ¼rdÃ¼rÃ¼lebilirlik hakkÄ±nda bir soru sorun..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Enerji VerimliliÄŸi KitabÄ± taranÄ±yor..."):
            response, source = rag_query_streamlit(prompt)
        
        st.markdown(response)
        
        with st.expander("KullanÄ±lan Kaynak (RAG Retrieval)"):
            st.code(source, language='text')

    st.session_state.messages.append({"role": "assistant", "content": response})
