import os
import streamlit as st
from google import genai
import math

# --- 1. YARDIMCI FONKSÄ°YON: Cosine Similarity Hesaplama ---
def cosine_similarity(vec1, vec2):
    dot_product = sum(v1 * v2 for v1, v2 in zip(vec1, vec2))
    magnitude_v1 = math.sqrt(sum(v**2 for v in vec1))
    magnitude_v2 = math.sqrt(sum(v**2 for v in vec2))
    if magnitude_v1 == 0 or magnitude_v2 == 0:
        return 0
    return dot_product / (magnitude_v1 * magnitude_v2)


# --- 2. ANA FONKSÄ°YON: VERÄ° HAZIRLAMA (Tekli Embed) ---
@st.cache_resource
def prepare_rag_data(api_key):

    file_path = "Enerji_verimliligi_eÄŸitim_kitabi.txt"  # TÃ¼rkÃ§e karakterleri sadeleÅŸtirdik

    if not os.path.exists(file_path):
        st.error(f"HATA: Veri dosyasÄ± '{file_path}' bulunamadÄ±.")
        return [], None

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
    except Exception as e:
        st.error(f"Dosya okuma hatasÄ±: {e}")
        return [], None

    # Metin ParÃ§alama
    text_chunks = []
    chunk_size = 2000
    for i in range(0, len(text), chunk_size):
        text_chunks.append(text[i:i + chunk_size])

    st.info(f"{len(text_chunks)} metin parÃ§asÄ± iÃ§in embedding oluÅŸturuluyor. LÃ¼tfen bekleyin...")

    embeddings = []
    try:
        client = genai.Client(api_key=api_key)

        progress_bar = st.progress(0, text="Embedding OluÅŸturuluyor...")

        # ğŸ”§ DÃœZELTME: 'content' yerine 'contents' kullanÄ±lmalÄ± (list olarak)
        for i, chunk in enumerate(text_chunks):
            response = client.models.embed_content(
                model='text-embedding-004',
                contents=[chunk]  # âœ… DoÄŸru parametre
            )
            # BazÄ± sÃ¼rÃ¼mlerde response['embedding'] olabilir, ama genelde bÃ¶yle dÃ¶ner:
            embedding_vector = response.embeddings[0].values if hasattr(response, 'embeddings') else response.embedding
            embeddings.append(embedding_vector)
            progress_bar.progress((i + 1) / len(text_chunks))

        progress_bar.empty()

        return text_chunks, embeddings

    except Exception as e:
        st.error(f"Embedding HatasÄ±: Veri gÃ¶mme iÅŸlemi baÅŸarÄ±sÄ±z oldu. Hata: {e}")
        return [], None


# --- 3. SORGULAMA FONKSÄ°YONU ---
def simple_query_streamlit(prompt, text_chunks, embeddings, api_key):

    try:
        client = genai.Client(api_key=api_key)

        # ğŸ”§ DÃœZELTME: prompt embedding kÄ±smÄ±nda da aynÄ± parametre dÃ¼zeltildi
        prompt_response = client.models.embed_content(
            model='text-embedding-004',
            contents=[prompt]  # âœ… burada da 'contents' olmalÄ±
        )

        prompt_embedding = (
            prompt_response.embeddings[0].values
            if hasattr(prompt_response, 'embeddings')
            else prompt_response.embedding
        )

        # --- En benzer 3 metin parÃ§asÄ±nÄ± bul ---
        similarity_scores = []
        for i, chunk_embedding in enumerate(embeddings):
            score = cosine_similarity(prompt_embedding, chunk_embedding)
            similarity_scores.append((score, i))

        similarity_scores.sort(key=lambda x: x[0], reverse=True)
        top_indices = [index for score, index in similarity_scores[:3]]
        retrieved_text = "\n\n---\n\n".join([text_chunks[i] for i in top_indices])

    except Exception as e:
        st.warning(f"VektÃ¶r Arama HatasÄ±: {e}. Basit aramaya geÃ§iliyor.")
        retrieved_text = "\n\n---\n\n".join(text_chunks[:3])

    # --- RAG ÃœRETÄ°M AÅAMASI ---
    try:
        client = genai.Client(api_key=api_key)

        rag_prompt = (
            f"Sen, 'Enerji VerimliliÄŸi EÄŸitim KitabÄ±'na dayalÄ± bir yapay zeka asistansÄ±n. "
            f"GÃ¶revin, aÅŸaÄŸÄ±daki 'KAYNAK METÄ°N'i kullanarak kullanÄ±cÄ± sorularÄ±nÄ± yanÄ±tlamaktÄ±r.\n\n"
            f"TALÄ°MATLAR:\n"
            f"1. **Ã–ncelik ve HalÃ¼sinasyon Engeli:** CevaplarÄ±nÄ± **KESÄ°NLÄ°KLE** sadece saÄŸlanan KAYNAK METÄ°N'deki bilgilerle sÄ±nÄ±rla. "
            f"Kaynak metnin dÄ±ÅŸÄ±ndaki kendi genel bilgini **ASLA** kullanma.\n"
            f"2. **AkÄ±l YÃ¼rÃ¼tme:** Sorunun cevabÄ± tek bir yerde geÃ§miyorsa, farklÄ± bilgileri birleÅŸtirerek kapsamlÄ± bir cevap oluÅŸtur.\n"
            f"3. **Reddetme:** Cevap kaynak metinde yoksa, "
            f"'ÃœzgÃ¼nÃ¼m, bu sorunun cevabÄ±nÄ± elimdeki Enerji VerimliliÄŸi EÄŸitim KitabÄ±nda bulamÄ±yorum.' de.\n\n"
            f"KAYNAK METÄ°N:\n---\n{retrieved_text}\n---\n\n"
            f"KULLANICI SORUSU: {prompt}"
        )

        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=rag_prompt
        )

        return response.text, retrieved_text

    except Exception as e:
        st.error(f"Sorgulama HatasÄ±: Gemini API Ã§aÄŸrÄ±sÄ±nda bir sorun oluÅŸtu. Hata: {e}")
        return "ÃœzgÃ¼nÃ¼m, sorgulama sÄ±rasÄ±nda bir hata oluÅŸtu.", retrieved_text
