import os 
import faiss
import numpy as np
import streamlit as st
from google import genai
from google.genai.errors import APIError 

# --- 1. YARDIMCI FONKSÄ°YON: METÄ°N PARÃ‡ALAMA (simple_chunking) ---
def simple_chunking(text, chunk_size=2000, chunk_overlap=200):
    text_chunks = []
    paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
    current_chunk = ""
    for paragraph in paragraphs:
        if len(current_chunk) + len(paragraph) + 2 <= chunk_size:
            if current_chunk:
                current_chunk += "\n\n"
            current_chunk += paragraph
        else:
            if current_chunk:
                text_chunks.append(current_chunk)
            current_chunk = paragraph
    if current_chunk:
        text_chunks.append(current_chunk)
    return text_chunks


# --- 2. ANA FONKSÄ°YON: RAG VERÄ°SÄ°NÄ° HAZIRLAMA VE Ä°NDEKSLENDÄ°RME ---

def prepare_rag_data(api_key):
    def create_empty_rag():
        empty_index = faiss.IndexFlatL2(1536) 
        return [], empty_index

    # 1. Metin DosyasÄ±nÄ± Kontrol Etme
    file_path = "Enerji_verimliligi_eÄŸitim_kitabi.txt"
    if not os.path.exists(file_path):
        st.error(f"HATA: Veri dosyasÄ± bulunamadÄ±: {file_path}")
        return create_empty_rag()

    with open(file_path, 'r', encoding='utf-8') as f:
        text = f.read()

    # 2. KalÄ±cÄ± Ä°ndeks Yolu TanÄ±mlama
    faiss_index_path = "faiss_index.bin"
    chunks_path = "text_chunks.npy"
    
    # 3. Ä°ndeksi Diskten YÃ¼kleme KontrolÃ¼ (HIZLI YOL)
    if os.path.exists(faiss_index_path) and os.path.exists(chunks_path):
        try:
            index = faiss.read_index(faiss_index_path)
            text_chunks = np.load(chunks_path, allow_pickle=True).tolist()
            return text_chunks, index # HÄ±zlÄ± ve baÅŸarÄ±lÄ± dÃ¶nÃ¼ÅŸ
        except Exception:
            st.warning("KayÄ±tlÄ± index yÃ¼klenirken hata oluÅŸtu. Yeniden oluÅŸturuluyor...")
            pass 

    # 4. Ä°ndeksi Yeniden OluÅŸturma (YAVAÅž YOL - ZAMAN AÅžIMI RÄ°SKÄ° YÃœKSEK)

    text_chunks = simple_chunking(text)
    embeddings_list = []
    
    try:
        client = genai.Client(api_key=api_key)
        st.info("FAISS indeksi API ile yeniden oluÅŸturuluyor. Bu iÅŸlem ZAMAN AÅžIMI riski taÅŸÄ±dÄ±ÄŸÄ±ndan, tamamlandÄ±ÄŸÄ±nda oluÅŸan index dosyalarÄ±nÄ± GitHub'a yÃ¼kleyin.")
        
        for chunk in text_chunks:
            response = client.models.embed_content(
                model='text-embedding-004',
                contents=chunk,  
            )
            # ðŸ’¥ DÃœZELTME: API'den gelen yanÄ±ttan vektÃ¶r verisini nesne eriÅŸimiyle Ã§ekiyoruz.
            # 'EmbedContentResponse' object is not subscriptable hatasÄ±nÄ± Ã§Ã¶zer.
            embeddings_list.append(response.embedding)
        
    except APIError as e:
        st.error(f"KRÄ°TÄ°K HATA: Gemini API'ye baÄŸlanÄ±rken sorun oluÅŸtu. AnahtarÄ±nÄ±zÄ± kontrol edin. Detay: {e}")
        return create_empty_rag() 
    except Exception as e:
        st.error(f"VektÃ¶rleÅŸtirme sÄ±rasÄ±nda beklenmeyen bir hata oluÅŸtu: {e}")
        return create_empty_rag()
    
    # 5. GÃ¼venlik KontrolÃ¼ ve FAISS Index OluÅŸturma
    if not embeddings_list:
        st.error("HATA: VektÃ¶r dizisi boÅŸ. API'den veri alÄ±namadÄ±.")
        return create_empty_rag()
        
    # Not: embeddings_list artÄ±k 1536 boyutlu vektÃ¶rlerin bir listesini tutar.
    embeddings_array = np.array(embeddings_list, dtype='float32')
    dimension = embeddings_array.shape[1] 

    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings_array)

    # 6. BaÅŸarÄ±lÄ± OluÅŸturmanÄ±n ArdÄ±ndan Ä°ndeksi Kaydetme
    try:
        faiss.write_index(index, faiss_index_path)
        np.save(chunks_path, text_chunks)
        st.success("FAISS indexi ve metin parÃ§alarÄ± diske kaydedildi.")
    except Exception as e:
        st.warning(f"OluÅŸturulan index diske kaydedilemedi: {e}. LÃ¼tfen indexi kendiniz oluÅŸturup GitHub'a yÃ¼kleyin.")

    return text_chunks, index