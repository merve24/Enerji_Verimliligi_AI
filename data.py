import os
import streamlit as st
from google import genai
# ğŸ¯ YENÄ° EKLEME: API'dan gelen hatalarÄ± yakalamak iÃ§in doÄŸru modÃ¼lÃ¼ iÃ§eri aktarÄ±yoruz.
from google.api_core import exceptions as core_exceptions 
import math

# --- 1. COSINE SIMILARITY ---
def cosine_similarity(vec1, vec2):
    dot_product = sum(v1 * v2 for v1, v2 in zip(vec1, vec2))
    magnitude_v1 = math.sqrt(sum(v**2 for v in vec1))
    magnitude_v2 = math.sqrt(sum(v**2 for v in vec2))
    if magnitude_v1 == 0 or magnitude_v2 == 0:
        return 0
    return dot_product / (magnitude_v1 * magnitude_v2)


# --- 2. RAG VERÄ° HAZIRLAMA ---
@st.cache_resource
def prepare_rag_data(api_key):

    file_path = "Enerji_verimliligi_eÄŸitim_kitabi.txt"  # TÃ¼rkÃ§e karakterleri sadeleÅŸtir

    if not os.path.exists(file_path):
        st.error(f"HATA: Veri dosyasÄ± '{file_path}' bulunamadÄ±.")
        return [], None

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
    except Exception as e:
        st.error(f"Dosya okuma hatasÄ±: {e}")
        return [], None

    # ğŸ”§ 1ï¸âƒ£ Chunk boyutunu bÃ¼yÃ¼t
    chunk_size = 5000
    text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]

    st.info(f"{len(text_chunks)} metin parÃ§asÄ± iÃ§in embedding oluÅŸturuluyor. LÃ¼tfen bekleyin...")

    embeddings = []
    try:
        client = genai.Client(api_key=api_key)
        progress_bar = st.progress(0, text="Embedding OluÅŸturuluyor...")

        # ğŸ”§ 2ï¸âƒ£ Daha kaliteli embedding modeli
        for i, chunk in enumerate(text_chunks):
            response = client.models.embed_content(
                model='text-embedding-004',  # Daha gÃ¼ncel embedding modeli
                contents=[chunk]
            )
            # Embedding format kontrolÃ¼
            if hasattr(response, "embeddings"):
                embedding_vector = response.embeddings[0].values
            else:
                embedding_vector = response.embedding
            embeddings.append(embedding_vector)
            progress_bar.progress((i + 1) / len(text_chunks))

        progress_bar.empty()
        return text_chunks, embeddings

    except Exception as e:
        st.error(f"Embedding HatasÄ±: Veri gÃ¶mme iÅŸlemi baÅŸarÄ±sÄ±z oldu. Hata: {e}")
        return [], None


# --- 3. SORGULAMA FONKSÄ°YONU ---
def simple_query_streamlit(prompt, text_chunks, embeddings, api_key):
    try:
        client = genai.Client(api_key=api_key)

        # ğŸ”§ 3ï¸âƒ£ Promptâ€™u Ä°ngilizceye Ã§evirerek embedding kalitesini artÄ±r
        prompt_for_embed = f"meaning of: {prompt} (in energy efficiency context)"

        prompt_response = client.models.embed_content(
            model='text-embedding-004',
            contents=[prompt_for_embed]
        )

        if hasattr(prompt_response, "embeddings"):
            prompt_embedding = prompt_response.embeddings[0].values
        else:
            prompt_embedding = prompt_response.embedding

        # ğŸ”§ 4ï¸âƒ£ En benzer 5 metin parÃ§asÄ±nÄ± al
        similarity_scores = []
        for i, chunk_embedding in enumerate(embeddings):
            score = cosine_similarity(prompt_embedding, chunk_embedding)
            similarity_scores.append((score, i))

        similarity_